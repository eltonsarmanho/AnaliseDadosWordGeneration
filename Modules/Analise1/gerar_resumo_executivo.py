#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RESUMO EXECUTIVO VISUAL - AN√ÅLISE AGREGADA POR ANO E FASE
Gera resumo executivo com tabelas e insights estrat√©gicos

Autor: Sistema de An√°lise WordGen
Data: 2025
"""

import pandas as pd
import numpy as np
import pathlib
from datetime import datetime
import math

# Configura√ß√µes de paths
BASE_DIR = pathlib.Path(__file__).parent.parent.parent.resolve()
DATA_DIR = BASE_DIR / "Data"
ANALISE_DIR = pathlib.Path(__file__).parent

# Arquivos de entrada
ARQUIVOS_TDE = {
    2: DATA_DIR / "tabela_bruta_fase2_TDE_wordgen.csv",
    3: DATA_DIR / "tabela_bruta_fase3_TDE_wordgen.csv",
    4: DATA_DIR / "tabela_bruta_fase4_TDE_wordgen.csv"
}

ARQUIVOS_VOCAB = {
    2: DATA_DIR / "tabela_bruta_fase2_vocabulario_wordgen.csv",
    3: DATA_DIR / "tabela_bruta_fase3_vocabulario_wordgen.csv", 
    4: DATA_DIR / "tabela_bruta_fase4_vocabulario_wordgen.csv"
}

# Mapeamento Fase -> Ano
FASE_ANO_MAP = {2: 2023, 3: 2024, 4: 2024}

def extrair_ano_turma(turma: str) -> str:
    """Extrai o ano da turma (5¬∫, 6¬∫, 7¬∫, 8¬∫, 9¬∫)"""
    if pd.isna(turma):
        return "N√£o identificado"
    
    turma_str = str(turma).upper()
    import re
    
    patterns = [
        r'(\d)\s*[¬∫¬∞]\s*ANO',  # "6¬∫ ANO", "7¬∞ ANO"
        r'(\d)[¬∫A-Z]',         # "6A", "7B"
        r'\b(\d)\b'            # Apenas d√≠gito
    ]
    
    for pattern in patterns:
        match = re.search(pattern, turma_str)
        if match:
            numero = int(match.group(1))
            if 5 <= numero <= 9:
                return f"{numero}¬∫ Ano"
    
    return "N√£o identificado"

def calcular_d_cohen(df: pd.DataFrame, col_pre: str = 'Score_Pre', col_pos: str = 'Score_Pos') -> float:
    """Calcula d de Cohen para medidas pr√© e p√≥s"""
    if df.empty:
        return np.nan
    
    pre = df[col_pre].dropna()
    pos = df[col_pos].dropna()
    
    if len(pre) < 2 or len(pos) < 2:
        return np.nan
    
    m_pre, m_pos = pre.mean(), pos.mean()
    sd_pre, sd_pos = pre.std(ddof=1), pos.std(ddof=1)
    
    n_pre, n_pos = len(pre), len(pos)
    if n_pre + n_pos - 2 <= 0:
        return np.nan
    
    pooled_sd = math.sqrt(((n_pre - 1) * sd_pre**2 + (n_pos - 1) * sd_pos**2) / (n_pre + n_pos - 2))
    
    if pooled_sd == 0:
        return np.nan
    
    return (m_pos - m_pre) / pooled_sd

def carregar_e_processar_dados():
    """Carrega e processa todos os dados"""
    # Carregar TDE
    df_tde_list = []
    for fase, arquivo in ARQUIVOS_TDE.items():
        if arquivo.exists():
            df = pd.read_csv(arquivo)
            df['Fase'] = fase
            df['Ano_Calendario'] = FASE_ANO_MAP[fase]
            df['Prova'] = 'TDE'
            df_tde_list.append(df)
    
    # Carregar Vocabul√°rio
    df_vocab_list = []
    for fase, arquivo in ARQUIVOS_VOCAB.items():
        if arquivo.exists():
            df = pd.read_csv(arquivo)
            df['Fase'] = fase
            df['Ano_Calendario'] = FASE_ANO_MAP[fase]
            df['Prova'] = 'VOCABULARIO'
            df_vocab_list.append(df)
    
    # Consolidar
    df_tde = pd.concat(df_tde_list, ignore_index=True) if df_tde_list else pd.DataFrame()
    df_vocab = pd.concat(df_vocab_list, ignore_index=True) if df_vocab_list else pd.DataFrame()
    
    # Processar
    for df in [df_tde, df_vocab]:
        if not df.empty:
            df['Ano_Turma'] = df['Turma'].apply(extrair_ano_turma)
            if 'Delta_Score' not in df.columns:
                df['Delta_Score'] = df['Score_Pos'] - df['Score_Pre']
    
    return df_tde, df_vocab

def criar_tabela_resumo(df_tde: pd.DataFrame, df_vocab: pd.DataFrame) -> pd.DataFrame:
    """Cria tabela resumo por dimens√µes principais"""
    resultados = []
    
    # Fun√ß√£o auxiliar para calcular m√©tricas
    def calcular_metricas(df_grupo, nome_grupo, prova):
        if df_grupo.empty:
            return None
        
        n = len(df_grupo)
        pre_mean = df_grupo['Score_Pre'].mean()
        pos_mean = df_grupo['Score_Pos'].mean()
        delta_mean = df_grupo['Delta_Score'].mean()
        d_cohen = calcular_d_cohen(df_grupo)
        
        # Distribui√ß√£o de resultados
        melhoria_pct = (df_grupo['Delta_Score'] > 0).sum() / n * 100
        declinio_pct = (df_grupo['Delta_Score'] < 0).sum() / n * 100
        
        # Classifica√ß√£o do d de Cohen
        if np.isnan(d_cohen):
            classe = "Sem dados"
            benchmark = False
        else:
            abs_d = abs(d_cohen)
            if abs_d < 0.2:
                classe = "Trivial"
            elif abs_d < 0.5:
                classe = "Pequeno"
            elif abs_d < 0.8:
                classe = "M√©dio"
            else:
                classe = "Grande"
            
            # Benchmark espec√≠fico
            if prova == 'TDE':
                benchmark = d_cohen >= 0.40
            else:  # VOCABULARIO
                benchmark = d_cohen >= 0.35
        
        return {
            'Dimensao': nome_grupo,
            'Prova': prova,
            'N': n,
            'Pre_Mean': pre_mean,
            'Pos_Mean': pos_mean,
            'Delta_Mean': delta_mean,
            'D_Cohen': d_cohen,
            'Classe_Efeito': classe,
            'Atinge_Benchmark': benchmark,
            'Melhoria_Pct': melhoria_pct,
            'Declinio_Pct': declinio_pct
        }
    
    # 1. An√°lise geral
    for df, prova in [(df_tde, 'TDE'), (df_vocab, 'VOCABULARIO')]:
        if not df.empty:
            resultado = calcular_metricas(df, 'GERAL', prova)
            if resultado:
                resultados.append(resultado)
    
    # 2. Por ano calend√°rio
    for ano in [2023, 2024]:
        for df, prova in [(df_tde, 'TDE'), (df_vocab, 'VOCABULARIO')]:
            if not df.empty:
                df_ano = df[df['Ano_Calendario'] == ano]
                if not df_ano.empty:
                    resultado = calcular_metricas(df_ano, f'ANO_{ano}', prova)
                    if resultado:
                        resultados.append(resultado)
    
    # 3. Por fase
    for fase in [2, 3, 4]:
        for df, prova in [(df_tde, 'TDE'), (df_vocab, 'VOCABULARIO')]:
            if not df.empty:
                df_fase = df[df['Fase'] == fase]
                if not df_fase.empty:
                    resultado = calcular_metricas(df_fase, f'FASE_{fase}', prova)
                    if resultado:
                        resultados.append(resultado)
    
    # 4. Por ano de turma
    for turma in ['6¬∫ Ano', '7¬∫ Ano', '8¬∫ Ano', '9¬∫ Ano']:
        for df, prova in [(df_tde, 'TDE'), (df_vocab, 'VOCABULARIO')]:
            if not df.empty:
                df_turma = df[df['Ano_Turma'] == turma]
                if not df_turma.empty:
                    resultado = calcular_metricas(df_turma, f'TURMA_{turma.replace("¬∫", "")}', prova)
                    if resultado:
                        resultados.append(resultado)
    
    # 5. Cruzamento Ano √ó Turma (principais)
    for ano in [2023, 2024]:
        for turma in ['6¬∫ Ano', '7¬∫ Ano', '8¬∫ Ano', '9¬∫ Ano']:
            for df, prova in [(df_tde, 'TDE'), (df_vocab, 'VOCABULARIO')]:
                if not df.empty:
                    df_cruzado = df[(df['Ano_Calendario'] == ano) & (df['Ano_Turma'] == turma)]
                    if not df_cruzado.empty:
                        resultado = calcular_metricas(df_cruzado, f'{ano}x{turma.replace("¬∫", "")}', prova)
                        if resultado:
                            resultados.append(resultado)
    
    return pd.DataFrame(resultados)

def gerar_insights_estrategicos(df_resumo: pd.DataFrame) -> list:
    """Gera insights estrat√©gicos baseados na an√°lise"""
    insights = []
    
    # Separar por prova
    tde_data = df_resumo[df_resumo['Prova'] == 'TDE']
    vocab_data = df_resumo[df_resumo['Prova'] == 'VOCABULARIO']
    
    # 1. An√°lise de tend√™ncias temporais
    insights.append("üîç INSIGHTS ESTRAT√âGICOS:")
    insights.append("=" * 25)
    
    # Comparar 2023 vs 2024
    tde_2023 = tde_data[tde_data['Dimensao'] == 'ANO_2023']['D_Cohen'].iloc[0] if len(tde_data[tde_data['Dimensao'] == 'ANO_2023']) > 0 else np.nan
    tde_2024 = tde_data[tde_data['Dimensao'] == 'ANO_2024']['D_Cohen'].iloc[0] if len(tde_data[tde_data['Dimensao'] == 'ANO_2024']) > 0 else np.nan
    
    vocab_2023 = vocab_data[vocab_data['Dimensao'] == 'ANO_2023']['D_Cohen'].iloc[0] if len(vocab_data[vocab_data['Dimensao'] == 'ANO_2023']) > 0 else np.nan
    vocab_2024 = vocab_data[vocab_data['Dimensao'] == 'ANO_2024']['D_Cohen'].iloc[0] if len(vocab_data[vocab_data['Dimensao'] == 'ANO_2024']) > 0 else np.nan
    
    if not np.isnan(tde_2023) and not np.isnan(tde_2024):
        melhoria_tde = tde_2024 - tde_2023
        insights.append(f"\n1. REVERS√ÉO TEMPORAL - TDE:")
        insights.append(f"   ‚Ä¢ 2023: d = {tde_2023:.3f}")
        insights.append(f"   ‚Ä¢ 2024: d = {tde_2024:.3f}")
        insights.append(f"   ‚Ä¢ Melhoria: {melhoria_tde:+.3f} pontos de efeito")
        
    if not np.isnan(vocab_2023) and not np.isnan(vocab_2024):
        melhoria_vocab = vocab_2024 - vocab_2023
        insights.append(f"\n2. REVERS√ÉO TEMPORAL - VOCABUL√ÅRIO:")
        insights.append(f"   ‚Ä¢ 2023: d = {vocab_2023:.3f}")
        insights.append(f"   ‚Ä¢ 2024: d = {vocab_2024:.3f}")
        insights.append(f"   ‚Ä¢ Melhoria: {melhoria_vocab:+.3f} pontos de efeito")
    
    # 3. Identificar grupos de risco e sucesso
    # TDE - piores e melhores
    tde_sorted = tde_data.sort_values('D_Cohen')
    piores_tde = tde_sorted.head(3)
    melhores_tde = tde_sorted.tail(3)
    
    insights.append(f"\n3. GRUPOS DE RISCO - TDE:")
    for _, row in piores_tde.iterrows():
        insights.append(f"   ‚Ä¢ {row['Dimensao']}: d = {row['D_Cohen']:.3f}, {row['Declinio_Pct']:.1f}% com decl√≠nio")
    
    insights.append(f"\n4. GRUPOS DE SUCESSO - TDE:")
    for _, row in melhores_tde.iterrows():
        insights.append(f"   ‚Ä¢ {row['Dimensao']}: d = {row['D_Cohen']:.3f}, {row['Melhoria_Pct']:.1f}% com melhoria")
    
    # VOCABUL√ÅRIO - piores e melhores
    vocab_sorted = vocab_data.sort_values('D_Cohen')
    piores_vocab = vocab_sorted.head(3)
    melhores_vocab = vocab_sorted.tail(3)
    
    insights.append(f"\n5. GRUPOS DE RISCO - VOCABUL√ÅRIO:")
    for _, row in piores_vocab.iterrows():
        insights.append(f"   ‚Ä¢ {row['Dimensao']}: d = {row['D_Cohen']:.3f}, {row['Declinio_Pct']:.1f}% com decl√≠nio")
    
    insights.append(f"\n6. GRUPOS DE SUCESSO - VOCABUL√ÅRIO:")
    for _, row in melhores_vocab.iterrows():
        insights.append(f"   ‚Ä¢ {row['Dimensao']}: d = {row['D_Cohen']:.3f}, {row['Melhoria_Pct']:.1f}% com melhoria")
    
    # 4. An√°lise de benchmarks
    tde_benchmark = tde_data[tde_data['Atinge_Benchmark'] == True]
    vocab_benchmark = vocab_data[vocab_data['Atinge_Benchmark'] == True]
    
    insights.append(f"\n7. ATINGIMENTO DE BENCHMARKS:")
    insights.append(f"   ‚Ä¢ TDE (‚â•0.40): {len(tde_benchmark)}/{len(tde_data)} grupos ({len(tde_benchmark)/len(tde_data)*100:.1f}%)")
    if len(tde_benchmark) > 0:
        for _, row in tde_benchmark.iterrows():
            insights.append(f"     - {row['Dimensao']}: d = {row['D_Cohen']:.3f} ‚úì")
    
    insights.append(f"   ‚Ä¢ VOCABUL√ÅRIO (‚â•0.35): {len(vocab_benchmark)}/{len(vocab_data)} grupos ({len(vocab_benchmark)/len(vocab_data)*100:.1f}%)")
    if len(vocab_benchmark) > 0:
        for _, row in vocab_benchmark.iterrows():
            insights.append(f"     - {row['Dimensao']}: d = {row['D_Cohen']:.3f} ‚úì")
    
    return insights

def formatar_tabela_resumo(df_resumo: pd.DataFrame) -> str:
    """Formata tabela resumo para o relat√≥rio"""
    tabela = []
    
    tabela.append("=" * 120)
    tabela.append("TABELA RESUMO EXECUTIVO - TODAS AS DIMENS√ïES")
    tabela.append("=" * 120)
    tabela.append("")
    
    # Cabe√ßalho
    header = f"{'Dimens√£o':<20} {'Prova':<11} {'N':<6} {'Pr√©':<6} {'P√≥s':<6} {'Delta':<7} {'d Cohen':<8} {'Classe':<8} {'Bench':<5} {'Melh%':<6} {'Decl%':<6}"
    tabela.append(header)
    tabela.append("-" * 120)
    
    # Dados ordenados por d de Cohen decrescente
    df_sorted = df_resumo.sort_values(['Prova', 'D_Cohen'], ascending=[True, False])
    
    for _, row in df_sorted.iterrows():
        benchmark_symbol = "‚úì" if row['Atinge_Benchmark'] else "‚úó"
        linha = (f"{row['Dimensao']:<20} {row['Prova']:<11} {row['N']:<6} "
                f"{row['Pre_Mean']:<6.1f} {row['Pos_Mean']:<6.1f} {row['Delta_Mean']:<7.2f} "
                f"{row['D_Cohen']:<8.3f} {row['Classe_Efeito']:<8} {benchmark_symbol:<5} "
                f"{row['Melhoria_Pct']:<6.1f} {row['Declinio_Pct']:<6.1f}")
        tabela.append(linha)
    
    tabela.append("-" * 120)
    tabela.append("")
    tabela.append("LEGENDA:")
    tabela.append("‚Ä¢ N = N√∫mero de participantes")
    tabela.append("‚Ä¢ Pr√©/P√≥s = Pontua√ß√£o m√©dia pr√©/p√≥s-teste")
    tabela.append("‚Ä¢ Delta = Diferen√ßa m√©dia (P√≥s - Pr√©)")
    tabela.append("‚Ä¢ d Cohen = Tamanho do efeito")
    tabela.append("‚Ä¢ Classe = Classifica√ß√£o do efeito (Cohen, 1988)")
    tabela.append("‚Ä¢ Bench = Atinge benchmark educacional (‚úì/‚úó)")
    tabela.append("‚Ä¢ Melh%/Decl% = Percentual com melhoria/decl√≠nio")
    tabela.append("")
    
    return "\n".join(tabela)

def main():
    """Fun√ß√£o principal"""
    print("=" * 80)
    print("üéØ RESUMO EXECUTIVO VISUAL - AN√ÅLISE AGREGADA POR ANO E FASE")
    print("=" * 80)
    
    # Carregar dados
    print("\nüìÇ Carregando e processando dados...")
    df_tde, df_vocab = carregar_e_processar_dados()
    
    if df_tde.empty and df_vocab.empty:
        print("‚ùå Nenhum dado foi carregado.")
        return
    
    print(f"  TDE: {len(df_tde)} registros")
    print(f"  Vocabul√°rio: {len(df_vocab)} registros")
    
    # Criar tabela resumo
    print("\nüìä Gerando tabela resumo...")
    df_resumo = criar_tabela_resumo(df_tde, df_vocab)
    
    # Gerar insights
    print("\nüîç Gerando insights estrat√©gicos...")
    insights = gerar_insights_estrategicos(df_resumo)
    
    # Formatear relat√≥rio
    print("\nüìã Formatando resumo executivo...")
    relatorio = []
    
    # Cabe√ßalho
    relatorio.extend([
        "=" * 120,
        "RESUMO EXECUTIVO VISUAL - AN√ÅLISE AGREGADA POR ANO E FASE",
        "WordGen - Desempenho TDE e Vocabul√°rio",
        "=" * 120,
        f"Data de Gera√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}",
        "",
        "CONTEXTO:",
        "‚Ä¢ Fase 2 (2023): Primeira implementa√ß√£o",
        "‚Ä¢ Fases 3-4 (2024): Refinamento e consolida√ß√£o", 
        "‚Ä¢ An√°lise multidimensional: 4.573 registros TDE, 4.393 registros Vocabul√°rio",
        "‚Ä¢ Benchmarks: TDE ‚â• 0.40, Vocabul√°rio ‚â• 0.35 (d de Cohen)",
        "",
    ])
    
    # Tabela resumo
    tabela_formatada = formatar_tabela_resumo(df_resumo)
    relatorio.append(tabela_formatada)
    
    # Insights estrat√©gicos
    relatorio.extend(insights)
    
    # Recomenda√ß√µes
    relatorio.extend([
        "\n" + "=" * 120,
        "RECOMENDA√á√ïES ESTRAT√âGICAS",
        "=" * 120,
        "",
        "üìà CURTO PRAZO (Pr√≥ximas Fases):",
        "1. Focar interven√ß√µes nos grupos 6¬∫ e 7¬∫ anos (maior decl√≠nio em 2023)",
        "2. Replicar estrat√©gias bem-sucedidas de 2024 (revers√£o positiva)",
        "3. Investigar fatores espec√≠ficos do 8¬∫ ano em Vocabul√°rio (decl√≠nio persistente)",
        "",
        "üî¨ M√âDIO PRAZO (Pesquisa e Desenvolvimento):",
        "4. An√°lise qualitativa dos fatores de melhoria entre 2023-2024",
        "5. Estudo de caso das escolas com melhor desempenho",
        "6. Desenvolvimento de interven√ß√µes espec√≠ficas por ano escolar",
        "",
        "üìä LONGO PRAZO (Monitoramento):",
        "7. Sistema de alerta precoce para grupos de risco",
        "8. Benchmarks adaptativos por contexto escolar",
        "9. An√°lise longitudinal individual para trajet√≥rias de aprendizagem",
        "",
        "=" * 120,
        "Relat√≥rio gerado automaticamente pelo Sistema de An√°lise WordGen",
        "Pr√≥xima atualiza√ß√£o recomendada: Ap√≥s coleta de nova fase",
        "=" * 120
    ])
    
    # Salvar
    arquivo_saida = ANALISE_DIR / f"resumo_executivo_visual_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(arquivo_saida, 'w', encoding='utf-8') as f:
        f.write("\n".join(relatorio))
    
    print(f"‚úÖ Resumo executivo salvo em: {arquivo_saida}")
    print(f"üìÑ Tamanho: {arquivo_saida.stat().st_size / 1024:.1f} KB")
    
    # Preview
    print("\n" + "=" * 80)
    print("PREVIEW DO RESUMO EXECUTIVO:")
    print("=" * 80)
    linhas = "\n".join(relatorio).split('\n')
    for linha in linhas[:40]:
        print(linha)
    
    if len(linhas) > 40:
        print(f"\n... e mais {len(linhas) - 40} linhas no arquivo completo.")
    
    print("\n‚úÖ PROCESSO CONCLU√çDO!")

if __name__ == "__main__":
    main()