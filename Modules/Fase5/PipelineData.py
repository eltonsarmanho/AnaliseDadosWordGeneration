#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Pipeline de Pr√©-processamento e Limpeza de Dados Educacionais Fase 5
Transforma dados brutos de avalia√ß√µes (L√≠ngua Portuguesa e Matem√°tica) 
em DataFrames anal√≠ticos limpos, pareados e no formato largo (wide).

Disciplinas: L√≠ngua Portuguesa e Matem√°tica
Fases: Pr√© e P√≥s
S√©ries: 6¬∫, 7¬∫, 8¬∫ e 9¬∫ Ano
"""

import pandas as pd
import numpy as np
import json
import hashlib
import unicodedata
from pathlib import Path
import warnings

warnings.filterwarnings('ignore')

class PipelineFase5:
    """
    Pipeline completo para processamento dos dados da Fase 5
    """
    
    def __init__(self, pasta_dados: str):
        """
        Inicializa o pipeline
        
        Args:
            pasta_dados: Caminho para a pasta com os dados da Fase 5
        """
        self.pasta_dados = Path(pasta_dados)
        self.pasta_saida = Path(__file__).parent / "Data"
        self.pasta_saida.mkdir(parents=True, exist_ok=True)
        
        # Arquivos de entrada
        self.arquivo_matematica = self.pasta_dados / "Matematica_CONSOLIDADO.csv"
        self.arquivo_portugues = self.pasta_dados / "Lingua_Portuguesa_CONSOLIDADO.csv"
        self.gabarito_matematica = self.pasta_dados / "Gabarito" / "Gabarito_Matematica.json"
        self.gabarito_portugues = self.pasta_dados / "Gabarito" / "Gabarito_Portugues.json"
        
        print("="*80)
        print("PIPELINE DE PR√â-PROCESSAMENTO - FASE 5")
        print("L√≠ngua Portuguesa e Matem√°tica (Pr√©/P√≥s)")
        print("="*80)
    
    def normalizar_texto(self, texto):
        """
        Normaliza texto: min√∫sculas, remove acentos e espa√ßos extras
        
        Args:
            texto: String a ser normalizada
            
        Returns:
            String normalizada
        """
        if pd.isna(texto) or texto == '':
            return texto
        
        # Converte para string se n√£o for
        texto = str(texto)
        
        # Min√∫sculas e remove espa√ßos
        texto = texto.lower().strip()
        
        # Remove acentos
        texto_nfd = unicodedata.normalize('NFKD', texto)
        texto_sem_acento = texto_nfd.encode('ascii', errors='ignore').decode('utf-8')
        
        return texto_sem_acento
    
    def padronizar_serie(self, serie):
        """
        Padroniza formato da s√©rie para corresponder ao JSON
        
        Args:
            serie: String da s√©rie (ex: "6 ANO")
            
        Returns:
            String padronizada (ex: "6¬∫ ANO")
        """
        if pd.isna(serie):
            return serie
        
        serie = str(serie).strip()
        
        # Mapeia formatos comuns
        mapeamento = {
            '6 ANO': '6¬∫ ANO',
            '7 ANO': '7¬∫ ANO', 
            '8 ANO': '8¬∫ ANO',
            '9 ANO': '9¬∫ ANO',
            '6¬∫ ANO': '6¬∫ ANO',
            '7¬∫ ANO': '7¬∫ ANO',
            '8¬∫ ANO': '8¬∫ ANO',
            '9¬∫ ANO': '9¬∫ ANO'
        }
        
        return mapeamento.get(serie.upper(), serie)
    
    def criar_id_aluno(self, row):
        """
        Cria ID √∫nico do aluno usando hash de dados identificadores
        
        Args:
            row: Linha do DataFrame
            
        Returns:
            String com hash MD5
        """
        # Usa nome, escola, s√©rie e turma para criar ID √∫nico (colunas em mai√∫scula)
        identificador = f"{row['Nome']}_{row['Escola']}_{row['Serie']}_{row['Turma']}"
        return hashlib.md5(identificador.encode()).hexdigest()[:12]
    
    def carregar_gabarito(self, arquivo_gabarito: Path):
        """
        Carrega gabarito do JSON
        
        Args:
            arquivo_gabarito: Caminho do arquivo JSON
            
        Returns:
            Dicion√°rio com gabaritos por s√©rie
        """
        with open(arquivo_gabarito, 'r', encoding='utf-8') as f:
            dados = json.load(f)
        
        gabaritos = {}
        for item in dados['Gabaritos']:
            serie = item['Serie']
            questoes = {}
            habilidades = {}
            
            for q in item['Questoes']:
                questao = f"Q{q['QUEST√ÉO']}"
                questoes[questao] = q['GABARITO']
                habilidades[questao] = q['HABILIDADE']
            
            gabaritos[serie] = {
                'questoes': questoes,
                'habilidades': habilidades
            }
        
        return gabaritos
    
    def padronizar_dataframe(self, df: pd.DataFrame):
        """
        Etapa 1: Padroniza√ß√£o inicial do DataFrame
        
        Args:
            df: DataFrame bruto
            
        Returns:
            DataFrame padronizado
        """
        print("   - Padronizando colunas de identifica√ß√£o...")
        
        # Cria ID do aluno ANTES de normalizar (precisa dos dados originais)
        df['ID_Aluno'] = df.apply(self.criar_id_aluno, axis=1)
        
        # Normaliza colunas de texto
        colunas_texto = ['Nome', 'Escola', 'Turma', 'Municipio', 'Estado']
        for col in colunas_texto:
            if col in df.columns:
                df[col] = df[col].apply(self.normalizar_texto)
        
        # Padroniza s√©rie
        if 'Serie' in df.columns:
            df['Serie'] = df['Serie'].apply(self.padronizar_serie)
        
        # Padroniza fase
        if 'Fase' in df.columns:
            df['Fase'] = df['Fase'].str.strip()
            df['Fase'] = df['Fase'].replace({'Pre': 'Pr√©', 'Pos': 'P√≥s'})
        
        print(f"   - DataFrame padronizado: {len(df)} registros")
        return df
    
    def funcao_de_correcao(self, grupo_serie, gabaritos):
        """
        Fun√ß√£o de corre√ß√£o para cada grupo por s√©rie
        
        Args:
            grupo_serie: DataFrame agrupado por s√©rie
            gabaritos: Dicion√°rio com gabaritos
            
        Returns:
            DataFrame com scores calculados
        """
        serie = grupo_serie.name
        
        if serie not in gabaritos:
            print(f"     ‚ö†Ô∏è  Gabarito n√£o encontrado para s√©rie: {serie}")
            return grupo_serie
        
        gabarito_serie = gabaritos[serie]
        questoes = gabarito_serie['questoes']
        habilidades = gabarito_serie['habilidades']
        
        print(f"     - Corrigindo {serie}: {len(questoes)} quest√µes")
        
        # Trata respostas nulas como erro (marca com 'X')
        for questao in questoes.keys():
            if questao in grupo_serie.columns:
                grupo_serie[questao] = grupo_serie[questao].fillna('X')
        
        # Gera colunas de pontua√ß√£o (P_Qn)
        for questao, gabarito in questoes.items():
            if questao in grupo_serie.columns:
                col_pontuacao = f"P_{questao}"
                grupo_serie[col_pontuacao] = np.where(
                    grupo_serie[questao] == gabarito, 1, 0
                )
        
        # Calcula total de acertos
        colunas_pontuacao = [f"P_{q}" for q in questoes.keys() if q in grupo_serie.columns]
        grupo_serie['Total_Acertos'] = grupo_serie[colunas_pontuacao].sum(axis=1)
        
        # Calcula scores por habilidade
        habilidades_unicas = set(habilidades.values())
        for hab in habilidades_unicas:
            questoes_habilidade = [
                f"P_{q}" for q, h in habilidades.items() 
                if h == hab and q in grupo_serie.columns
            ]
            if questoes_habilidade:
                grupo_serie[f'Total_Acertos_{hab}'] = grupo_serie[questoes_habilidade].sum(axis=1)
        
        return grupo_serie
    
    def corrigir_e_pontuar(self, df: pd.DataFrame, gabaritos: dict):
        """
        Etapa 2: Corre√ß√£o e gera√ß√£o de scores
        
        Args:
            df: DataFrame padronizado
            gabaritos: Dicion√°rio com gabaritos
            
        Returns:
            DataFrame com scores calculados
        """
        print("   - Iniciando corre√ß√£o por s√©rie...")
        
        df_corrigido = df.groupby('Serie').apply(
            self.funcao_de_correcao, 
            gabaritos=gabaritos
        ).reset_index(drop=True)
        
        print(f"   - Corre√ß√£o conclu√≠da: {len(df_corrigido)} registros")
        return df_corrigido
    
    def filtrar_registros_invalidos(self, df: pd.DataFrame):
        """
        Etapa 3: Filtragem de registros inv√°lidos
        
        Args:
            df: DataFrame com scores
            
        Returns:
            DataFrame filtrado
        """
        print("   - Iniciando filtragem de registros inv√°lidos...")
        
        registros_inicial = len(df)
        
        # Identifica colunas de quest√µes
        colunas_questoes = [col for col in df.columns if col.startswith('Q') and not col.startswith('Q_')]
        
        # Filtro 1: Remove testes em branco
        print("     - Filtro 1: Removendo testes em branco...")
        df_filtrado = df.dropna(subset=colunas_questoes, how='all')
        removidos_branco = registros_inicial - len(df_filtrado)
        print(f"       Removidos {removidos_branco} testes em branco")
        
        # Filtro 2: Remove duplicatas Aluno-Fase
        print("     - Filtro 2: Removendo duplicatas Aluno-Fase...")
        antes_duplicatas = len(df_filtrado)
        df_filtrado = df_filtrado.drop_duplicates(subset=['ID_Aluno', 'Fase'], keep='first')
        removidos_duplicatas = antes_duplicatas - len(df_filtrado)
        print(f"       Removidos {removidos_duplicatas} registros duplicados")
        
        # Filtro 3: Mant√©m apenas pares completos (Pr√© E P√≥s)
        print("     - Filtro 3: Mantendo apenas pares completos (Pr√© E P√≥s)...")
        fase_counts = df_filtrado.groupby('ID_Aluno')['Fase'].nunique()
        alunos_completos = fase_counts[fase_counts == 2].index
        df_pareado = df_filtrado[df_filtrado['ID_Aluno'].isin(alunos_completos)]
        
        removidos_incompletos = len(df_filtrado) - len(df_pareado)
        print(f"       Removidos {removidos_incompletos} alunos sem par Pr√©/P√≥s")
        
        # Estat√≠sticas finais
        print(f"   - Filtragem conclu√≠da:")
        print(f"     * Registros iniciais: {registros_inicial}")
        print(f"     * Registros finais: {len(df_pareado)}")
        print(f"     * Alunos √∫nicos: {df_pareado['ID_Aluno'].nunique()}")
        print(f"     * Taxa de reten√ß√£o: {len(df_pareado)/registros_inicial*100:.1f}%")
        
        return df_pareado
    
    def pivotar_para_largo(self, df: pd.DataFrame):
        """
        Etapa 4: Reestrutura√ß√£o para formato largo
        
        Args:
            df: DataFrame pareado
            
        Returns:
            DataFrame no formato largo
        """
        print("   - Pivotando para formato largo...")
        
        # Identifica colunas de identifica√ß√£o
        colunas_id = ['ID_Aluno', 'Nome', 'Escola', 'Serie', 'Turma', 'Municipio', 'Estado']
        
        # Identifica colunas de valores (scores)
        colunas_valores = [col for col in df.columns if col.startswith('Total_Acertos')]
        
        # Adiciona colunas P_Q individuais se existirem
        colunas_p = [col for col in df.columns if col.startswith('P_Q')]
        colunas_valores.extend(colunas_p)
        
        print(f"     - Pivotando {len(colunas_valores)} colunas de valores")
        
        # Pivota
        df_largo = df.pivot_table(
            index=colunas_id,
            columns='Fase',
            values=colunas_valores,
            aggfunc='first'
        ).reset_index()
        
        # Limpa nomes das colunas (remove MultiIndex)
        df_largo.columns = [
            f"{col[0]}_{col[1]}" if col[1] else col[0] 
            for col in df_largo.columns
        ]
        
        print(f"   - Formato largo criado: {len(df_largo)} registros")
        return df_largo
    
    def calcular_deltas(self, df_largo: pd.DataFrame):
        """
        Etapa 5: C√°lculos finais (deltas)
        
        Args:
            df_largo: DataFrame no formato largo
            
        Returns:
            DataFrame com deltas calculados
        """
        print("   - Calculando deltas (evolu√ß√£o Pr√© ‚Üí P√≥s)...")
        
        deltas_calculados = 0
        
        # Encontra pares de colunas Pr√©/P√≥s
        colunas = df_largo.columns.tolist()
        colunas_pre = [col for col in colunas if col.endswith('_Pr√©')]
        
        for col_pre in colunas_pre:
            base_name = col_pre.replace('_Pr√©', '')
            col_pos = f"{base_name}_P√≥s"
            
            if col_pos in colunas:
                col_delta = f"Delta_{base_name}"
                df_largo[col_delta] = df_largo[col_pos] - df_largo[col_pre]
                deltas_calculados += 1
        
        print(f"     - {deltas_calculados} deltas calculados")
        return df_largo
    
    def processar_disciplina(self, arquivo_csv: Path, arquivo_gabarito: Path, nome_disciplina: str):
        """
        Processa uma disciplina completa
        
        Args:
            arquivo_csv: Caminho do CSV de dados
            arquivo_gabarito: Caminho do JSON de gabarito
            nome_disciplina: Nome da disciplina
            
        Returns:
            DataFrame processado
        """
        print(f"\n{'='*60}")
        print(f"PROCESSANDO: {nome_disciplina.upper()}")
        print(f"{'='*60}")
        
        # Etapa 1: Carregamento e padroniza√ß√£o
        print("ETAPA 1: Carregamento e Padroniza√ß√£o")
        df = pd.read_csv(arquivo_csv)
        print(f"   - Dados carregados: {len(df)} registros")
        
        gabaritos = self.carregar_gabarito(arquivo_gabarito)
        print(f"   - Gabaritos carregados: {len(gabaritos)} s√©ries")
        
        df = self.padronizar_dataframe(df)
        
        # Etapa 2: Corre√ß√£o e pontua√ß√£o
        print("\nETAPA 2: Corre√ß√£o e Gera√ß√£o de Scores")
        df = self.corrigir_e_pontuar(df, gabaritos)
        
        # Etapa 3: Filtragem
        print("\nETAPA 3: Filtragem de Registros Inv√°lidos")
        df = self.filtrar_registros_invalidos(df)
        
        # Etapa 4: Pivotagem
        print("\nETAPA 4: Reestrutura√ß√£o para Formato Largo")
        df_largo = self.pivotar_para_largo(df)
        
        # Etapa 5: C√°lculos finais
        print("\nETAPA 5: C√°lculos Finais")
        df_final = self.calcular_deltas(df_largo)
        
        # Salva resultado
        nome_arquivo = f"df_{nome_disciplina.lower().replace(' ', '_')}_analitico.csv"
        arquivo_saida = self.pasta_saida / nome_arquivo
        df_final.to_csv(arquivo_saida, index=False)
        
        print(f"\n‚úÖ {nome_disciplina} processada com sucesso!")
        print(f"   - Arquivo salvo: {arquivo_saida}")
        print(f"   - Registros finais: {len(df_final)}")
        print(f"   - Colunas: {len(df_final.columns)}")
        
        return df_final
    
    def executar_pipeline(self):
        """
        Executa o pipeline completo para ambas as disciplinas
        """
        print("Iniciando pipeline para Fase 5...")
        print(f"Pasta de dados: {self.pasta_dados}")
        print(f"Pasta de sa√≠da: {self.pasta_saida}")
        
        resultados = {}
        
        # Processa Matem√°tica
        if self.arquivo_matematica.exists() and self.gabarito_matematica.exists():
            resultados['matematica'] = self.processar_disciplina(
                self.arquivo_matematica,
                self.gabarito_matematica,
                "Matem√°tica"
            )
        else:
            print("‚ùå Arquivos de Matem√°tica n√£o encontrados")
        
        # Processa L√≠ngua Portuguesa
        if self.arquivo_portugues.exists() and self.gabarito_portugues.exists():
            resultados['portugues'] = self.processar_disciplina(
                self.arquivo_portugues,
                self.gabarito_portugues,
                "L√≠ngua Portuguesa"
            )
        else:
            print("‚ùå Arquivos de L√≠ngua Portuguesa n√£o encontrados")
        
        # Resumo final
        print(f"\n{'='*80}")
        print("PIPELINE CONCLU√çDO!")
        print(f"{'='*80}")
        
        for disciplina, df in resultados.items():
            print(f"‚úÖ {disciplina.title()}: {len(df)} registros processados")
        
        print(f"\nüìÅ Arquivos salvos em: {self.pasta_saida}")
        
        return resultados

def main():
    """Fun√ß√£o principal"""
    # Caminho para os dados da Fase 5
    pasta_dados = "/home/nees/Documents/VSCodigo/AnaliseDadosWordGeneration/Data/Fase 5"
    
    # Cria e executa pipeline
    pipeline = PipelineFase5(pasta_dados)
    resultados = pipeline.executar_pipeline()
    
    return resultados

if __name__ == "__main__":
    main()