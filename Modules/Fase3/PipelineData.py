import pandas
import os
import sys
import pathlib
from scipy import stats
import numpy as np
from datetime import datetime
import io

# Adiciona o diret√≥rio atual ao sys.path para permitir importa√ß√µes relativas
current_dir = pathlib.Path(__file__).parent.parent.parent.resolve()
print(f"Diret√≥rio atual: {current_dir}")
current_dir = str(current_dir) + '/Data'
nome = "RESULTADOS_WordGen_TDE_Vocabulario_2024-1_Fase_3.xlsx"
arquivo_excel = os.path.join(current_dir, nome)
print(f"Arquivo Excel localizado: {arquivo_excel}")

# Buffer para capturar toda a sa√≠da
output_buffer = io.StringIO()
original_stdout = sys.stdout

def capture_print(*args, **kwargs):
    """Fun√ß√£o para capturar prints tanto no console quanto no buffer"""
    print(*args, **kwargs, file=original_stdout)  # Console
    print(*args, **kwargs, file=output_buffer)    # Buffer

# Substituir print temporariamente
sys.stdout = output_buffer

# Iniciar relat√≥rio
capture_print("="*80)
capture_print("PIPELINE DE AN√ÅLISE - VOCABUL√ÅRIO WORDGEN - ETAPA 3")
capture_print("BENCHMARKS EDUCACIONAIS ESPEC√çFICOS")
capture_print("="*80)
capture_print(f"Data/Hora de execu√ß√£o: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
capture_print("="*80)

def interpretar_effect_size_benchmarks(effect_size):
    """
    Interpreta√ß√£o baseada em m√∫ltiplos benchmarks educacionais
    
    Refer√™ncias:
    - Cohen (1988): Statistical Power Analysis for the Behavioral Sciences
    - Hattie (2009): Visible Learning: A Synthesis of Over 800 Meta-Analyses
    - Marulis & Neuman (2010): The effects of vocabulary intervention on young children's word learning
    """
    abs_es = abs(effect_size)
    
    # Classifica√ß√£o prim√°ria (Cohen)
    if abs_es < 0.2:
        cohen_categoria = "Trivial"
        cohen_descricao = "Diferen√ßa praticamente impercept√≠vel"
    elif abs_es < 0.5:
        cohen_categoria = "Pequeno"
        cohen_descricao = "Detect√°vel por observador treinado"
    elif abs_es < 0.8:
        cohen_categoria = "M√©dio"
        cohen_descricao = "Diferen√ßa vis√≠vel ao olho nu"
    else:
        cohen_categoria = "Grande"
        cohen_descricao = "Diferen√ßa √≥bvia para qualquer pessoa"
    
    # Benchmark Hattie (2009) - Educa√ß√£o
    if abs_es >= 0.6:
        hattie_categoria = "Excelente"
        hattie_status = "‚úì‚úì"
        hattie_cor = "üü¢"
    elif abs_es >= 0.4:
        hattie_categoria = "Bom Resultado"
        hattie_status = "‚úì"
        hattie_cor = "üü°"
    else:
        hattie_categoria = "Abaixo do Esperado"
        hattie_status = "‚ö†"
        hattie_cor = "üî¥"
    
    # Benchmark Marulis & Neuman (2010) - Vocabul√°rio
    if abs_es >= 0.50:
        vocabulario_categoria = "Substancial"
        vocabulario_status = "‚úì‚úì"
        vocabulario_cor = "üü¢"
    elif abs_es >= 0.35:
        vocabulario_categoria = "Educacionalmente Significativo"
        vocabulario_status = "‚úì"
        vocabulario_cor = "üü°"
    else:
        vocabulario_categoria = "N√£o Significativo"
        vocabulario_status = "‚ö†"
        vocabulario_cor = "üî¥"
    
    # Classifica√ß√£o final integrada
    if abs_es >= 0.6:
        classificacao_final = "EXCELENTE"
        impacto_educacional = "Transformador - resultado excepcional"
    elif abs_es >= 0.4:
        classificacao_final = "BOM"
        impacto_educacional = "Substancial - interven√ß√£o eficaz"
    elif abs_es >= 0.35:
        classificacao_final = "ADEQUADO"
        impacto_educacional = "Moderado - ganho educacional detect√°vel"
    elif abs_es >= 0.2:
        classificacao_final = "MARGINAL"
        impacto_educacional = "Pequeno - ganho limitado"
    else:
        classificacao_final = "INSUFICIENTE"
        impacto_educacional = "Trivial - sem impacto pr√°tico"
    
    return {
        'effect_size': effect_size,
        'abs_effect_size': abs_es,
        'cohen_categoria': cohen_categoria,
        'cohen_descricao': cohen_descricao,
        'hattie_categoria': hattie_categoria,
        'hattie_status': hattie_status,
        'hattie_cor': hattie_cor,
        'vocabulario_categoria': vocabulario_categoria,
        'vocabulario_status': vocabulario_status,
        'vocabulario_cor': vocabulario_cor,
        'classificacao_final': classificacao_final,
        'impacto_educacional': impacto_educacional
    }

def apresentar_benchmarks():
    """Apresenta os frameworks te√≥ricos dos benchmarks"""
    capture_print("\n1. FRAMEWORKS TE√ìRICOS E BENCHMARKS")
    capture_print("-"*60)
    
    capture_print("COHEN (1988) - Statistical Power Analysis:")
    capture_print("  üìä Base cient√≠fica: >100.000 cita√ß√µes")
    capture_print("  ‚Ä¢ d = 0.2: Pequeno (detect√°vel por especialista)")
    capture_print("  ‚Ä¢ d = 0.5: M√©dio (vis√≠vel ao olho nu)")
    capture_print("  ‚Ä¢ d = 0.8: Grande (√≥bvio para qualquer pessoa)")
    
    capture_print("\nHATTIE (2009) - Visible Learning (Educa√ß√£o):")
    capture_print("  üìä Base: 800+ meta-an√°lises educacionais")
    capture_print("  ‚Ä¢ d ‚â• 0.6: üü¢ Excelente resultado educacional")
    capture_print("  ‚Ä¢ d ‚â• 0.4: üü° Bom resultado educacional (threshold)")
    capture_print("  ‚Ä¢ d < 0.4: üî¥ Abaixo do esperado para educa√ß√£o")
    
    capture_print("\nMARULIS & NEUMAN (2010) - Vocabul√°rio Espec√≠fico:")
    capture_print("  üìä Base: Meta-an√°lise com 67 estudos de vocabul√°rio")
    capture_print("  ‚Ä¢ d ‚â• 0.50: üü¢ Substancial para vocabul√°rio")
    capture_print("  ‚Ä¢ d ‚â• 0.35: üü° Educacionalmente significativo")
    capture_print("  ‚Ä¢ d < 0.35: üî¥ N√£o significativo para vocabul√°rio")

def analisar_com_benchmarks(cohen_d):
    """An√°lise detalhada com todos os benchmarks"""
    interpretacao = interpretar_effect_size_benchmarks(cohen_d)
    
    capture_print(f"\n2. AN√ÅLISE COM BENCHMARKS EDUCACIONAIS")
    capture_print("-"*60)
    
    capture_print(f"Effect Size observado: {interpretacao['effect_size']:.4f}")
    capture_print(f"Effect Size absoluto: {interpretacao['abs_effect_size']:.4f}")
    
    capture_print(f"\nCLASSIFICA√á√ÉO FINAL: {interpretacao['classificacao_final']}")
    capture_print(f"Impacto educacional: {interpretacao['impacto_educacional']}")
    
    capture_print(f"\nBENCHMARKS APLICADOS:")
    capture_print(f"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
    capture_print(f"‚îÇ COHEN (1988)                                            ‚îÇ")
    capture_print(f"‚îÇ Categoria: {interpretacao['cohen_categoria']:<20} ‚îÇ")
    capture_print(f"‚îÇ Descri√ß√£o: {interpretacao['cohen_descricao']:<35} ‚îÇ")
    capture_print(f"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
    capture_print(f"‚îÇ HATTIE (2009) - EDUCA√á√ÉO                               ‚îÇ")
    capture_print(f"‚îÇ Status: {interpretacao['hattie_cor']} {interpretacao['hattie_categoria']:<25} {interpretacao['hattie_status']:<5} ‚îÇ")
    capture_print(f"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
    capture_print(f"‚îÇ MARULIS & NEUMAN (2010) - VOCABUL√ÅRIO                  ‚îÇ")
    capture_print(f"‚îÇ Status: {interpretacao['vocabulario_cor']} {interpretacao['vocabulario_categoria']:<25} {interpretacao['vocabulario_status']:<5} ‚îÇ")
    capture_print(f"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
    
    return interpretacao

def recomendacoes_baseadas_benchmarks(interpretacao):
    """Gerar recomenda√ß√µes baseadas nos benchmarks"""
    capture_print(f"\n3. RECOMENDA√á√ïES BASEADAS EM EVID√äNCIAS")
    capture_print("-"*60)
    
    classificacao = interpretacao['classificacao_final']
    effect_size = interpretacao['abs_effect_size']
    
    if classificacao == "EXCELENTE":
        capture_print("üéØ ESTRAT√âGIA: MANUTEN√á√ÉO E EXPANS√ÉO")
        capture_print("‚úÖ Resultado excepcional - acima de todos os benchmarks")
        capture_print("üìà A√ß√µes recomendadas:")
        capture_print("   ‚Ä¢ Documentar e sistematizar a metodologia aplicada")
        capture_print("   ‚Ä¢ Replicar a interven√ß√£o em outros contextos")
        capture_print("   ‚Ä¢ Treinar outros educadores com base nesta experi√™ncia")
        capture_print("   ‚Ä¢ Publicar resultados como modelo de refer√™ncia")
        
    elif classificacao == "BOM":
        capture_print("üéØ ESTRAT√âGIA: OTIMIZA√á√ÉO E CONSOLIDA√á√ÉO")
        capture_print("‚úÖ Bom resultado educacional - atende benchmark Hattie")
        capture_print("üìà A√ß√µes recomendadas:")
        capture_print("   ‚Ä¢ Manter a metodologia atual")
        capture_print("   ‚Ä¢ Buscar pequenos ajustes para alcan√ßar d‚â•0.6")
        capture_print("   ‚Ä¢ Monitorar sustentabilidade dos ganhos")
        capture_print("   ‚Ä¢ Considerar intensifica√ß√£o da interven√ß√£o")
        
    elif classificacao == "ADEQUADO":
        capture_print("üéØ ESTRAT√âGIA: INTENSIFICA√á√ÉO MODERADA")
        capture_print("‚ö†Ô∏è Resultado adequado para vocabul√°rio, mas abaixo do ideal educacional")
        capture_print("üìà A√ß√µes recomendadas:")
        capture_print("   ‚Ä¢ Aumentar frequ√™ncia ou dura√ß√£o da interven√ß√£o")
        capture_print("   ‚Ä¢ Adicionar componentes complementares")
        capture_print("   ‚Ä¢ Revisar adequa√ß√£o ao p√∫blico-alvo")
        capture_print("   ‚Ä¢ Meta: alcan√ßar d‚â•0.4 (benchmark Hattie)")
        
    elif classificacao == "MARGINAL":
        capture_print("üéØ ESTRAT√âGIA: REVIS√ÉO METODOL√ìGICA")
        capture_print("‚ö†Ô∏è Ganho detect√°vel mas insuficiente para impacto educacional")
        capture_print("üìà A√ß√µes recomendadas:")
        capture_print("   ‚Ä¢ Revisar fundamenta√ß√£o te√≥rica da interven√ß√£o")
        capture_print("   ‚Ä¢ Avaliar adequa√ß√£o ao contexto e idade")
        capture_print("   ‚Ä¢ Considerar mudan√ßas metodol√≥gicas significativas")
        capture_print("   ‚Ä¢ Investigar fatores contextuais limitantes")
        
    else:  # INSUFICIENTE
        capture_print("üéØ ESTRAT√âGIA: REFORMULA√á√ÉO COMPLETA")
        capture_print("‚ùå Resultado insuficiente - sem impacto educacional detect√°vel")
        capture_print("üìà A√ß√µes recomendadas:")
        capture_print("   ‚Ä¢ Reformular completamente a interven√ß√£o")
        capture_print("   ‚Ä¢ Revisar pressupostos te√≥ricos")
        capture_print("   ‚Ä¢ Considerar interven√ß√µes alternativas")
        capture_print("   ‚Ä¢ Avaliar pr√©-requisitos e condi√ß√µes de implementa√ß√£o")
    
    # Compara√ß√£o com literatura
    capture_print(f"\n4. CONTEXTO NA LITERATURA CIENT√çFICA")
    capture_print("-"*60)
    
    if effect_size >= 0.6:
        capture_print("üìö Seu resultado est√° no TOP 25% dos estudos educacionais")
        capture_print("üèÜ Resultado compar√°vel aos melhores programas de vocabul√°rio")
        
    elif effect_size >= 0.4:
        capture_print("üìö Seu resultado est√° acima da m√©dia dos estudos educacionais")
        capture_print("üëç Resultado superior a muitos programas escolares padr√£o")
        
    elif effect_size >= 0.35:
        capture_print("üìö Seu resultado est√° na m√©dia dos estudos de vocabul√°rio")
        capture_print("üí° Resultado t√≠pico de interven√ß√µes educacionais eficazes")
        
    elif effect_size >= 0.2:
        capture_print("üìö Seu resultado est√° abaixo da m√©dia desej√°vel")
        capture_print("‚ö†Ô∏è Muitos estudos reportam efeitos maiores")
        
    else:
        capture_print("üìö Seu resultado est√° significativamente abaixo da literatura")
        capture_print("üîç Revis√£o metodol√≥gica √© altamente recomendada")

# Carregar dados
df_pre = pandas.read_excel(arquivo_excel, sheet_name='pre')
df_pos = pandas.read_excel(arquivo_excel, sheet_name='pos')

capture_print("Dados carregados com sucesso.")

# Verificar IDs em comum entre df_pre e df_pos
ids_pre = set(df_pre['id'])
ids_pos = set(df_pos['id'])
ids_comuns = ids_pre.intersection(ids_pos)

capture_print(f"\nVERIFICA√á√ÉO DOS DADOS:")
capture_print(f"Total de IDs em df_pre: {len(ids_pre)}")
capture_print(f"Total de IDs em df_pos: {len(ids_pos)}")
capture_print(f"IDs em comum: {len(ids_comuns)}")

# Filtrar os DataFrames para manter apenas os IDs em comum
df_pre_filtrado = df_pre[df_pre['id'].isin(ids_comuns)]
df_pos_filtrado = df_pos[df_pos['id'].isin(ids_comuns)]

capture_print(f"\nAp√≥s filtrar por IDs em comum:")
capture_print(f"Registros em df_pre_filtrado: {len(df_pre_filtrado)}")
capture_print(f"Registros em df_pos_filtrado: {len(df_pos_filtrado)}")

# Descri√ß√£o estat√≠stica dos dados
capture_print("\n" + "="*60)
capture_print("DESCRI√á√ÉO ESTAT√çSTICA - PR√â-INTERVEN√á√ÉO")
capture_print("="*60)
capture_print(df_pre_filtrado.describe())

capture_print("\n" + "="*60)
capture_print("DESCRI√á√ÉO ESTAT√çSTICA - P√ìS-INTERVEN√á√ÉO")
capture_print("="*60)
capture_print(df_pos_filtrado.describe())

# An√°lise das perguntas Q1 a Q40
colunas_interesse = [col for col in df_pre_filtrado.columns if col.startswith('Q') or 'Score' in col or 'score' in col]

if colunas_interesse:
    # Separar colunas Q (booleanas) das colunas Score
    colunas_q = [col for col in colunas_interesse if col.startswith('Q')]
    colunas_score = [col for col in colunas_interesse if 'Score' in col or 'score' in col]
    
    # Converter colunas Q para booleano
    df_pre_bool = df_pre_filtrado[colunas_q].copy()
    df_pos_bool = df_pos_filtrado[colunas_q].copy()
    
    for col in colunas_q:
        df_pre_bool[col] = pandas.to_numeric(df_pre_filtrado[col], errors='coerce').fillna(0)
        df_pos_bool[col] = pandas.to_numeric(df_pos_filtrado[col], errors='coerce').fillna(0)
        df_pre_bool[col] = (df_pre_bool[col] > 0).astype(int)
        df_pos_bool[col] = (df_pos_bool[col] > 0).astype(int)
    
    # capture_print("\n" + "="*60)
    # capture_print("AN√ÅLISE ESTAT√çSTICA - PERGUNTAS BOOLEANAS (PR√â)")
    # capture_print("="*60)
    # capture_print("Propor√ß√£o de acertos por pergunta:")
    # capture_print(df_pre_bool.mean().round(3))
    # capture_print("\nTotal de acertos por pergunta:")
    # capture_print(df_pre_bool.sum())
    # capture_print(f"\nTotal de participantes: {len(df_pre_bool)}")
    
    # capture_print("\n" + "="*60)
    # capture_print("AN√ÅLISE ESTAT√çSTICA - PERGUNTAS BOOLEANAS (P√ìS)")
    # capture_print("="*60)
    # capture_print("Propor√ß√£o de acertos por pergunta:")
    # capture_print(df_pos_bool.mean().round(3))
    # capture_print("\nTotal de acertos por pergunta:")
    # capture_print(df_pos_bool.sum())
    # capture_print(f"\nTotal de participantes: {len(df_pos_bool)}")
    
    # An√°lise dos Scores
    if colunas_score:
        capture_print("\n" + "="*60)
        capture_print("DESCRI√á√ÉO ESTAT√çSTICA - SCORE FINAL")
        capture_print("="*60)
        capture_print("PR√â-INTERVEN√á√ÉO:")
        capture_print(df_pre_filtrado[colunas_score].describe())
        capture_print("\nP√ìS-INTERVEN√á√ÉO:")
        capture_print(df_pos_filtrado[colunas_score].describe())
    
    # Compara√ß√£o geral de desempenho
    df_pre_bool_sorted = df_pre_bool.set_index(df_pre_filtrado['id']).sort_index()
    df_pos_bool_sorted = df_pos_bool.set_index(df_pos_filtrado['id']).sort_index()
    
    acertos_pre = df_pre_bool_sorted.sum(axis=1)
    acertos_pos = df_pos_bool_sorted.sum(axis=1)
    
    capture_print("\n" + "="*60)
    capture_print("COMPARA√á√ÉO DE DESEMPENHO GERAL")
    capture_print("="*60)
    capture_print(f"M√©dia de acertos PR√â: {acertos_pre.mean():.2f} ¬± {acertos_pre.std():.2f}")
    capture_print(f"M√©dia de acertos P√ìS: {acertos_pos.mean():.2f} ¬± {acertos_pos.std():.2f}")
    capture_print(f"Diferen√ßa m√©dia: {(acertos_pos.mean() - acertos_pre.mean()):.2f}")
    
    # Apresentar benchmarks te√≥ricos
    apresentar_benchmarks()
    
    # TESTES ESTAT√çSTICOS
    capture_print("\n" + "="*80)
    capture_print("TESTES ESTAT√çSTICOS COMPARATIVOS")
    capture_print("="*80)
    
    # 1. Teste de normalidade e teste pareado
    try:
        stat_pre, p_pre = stats.shapiro(acertos_pre)
        stat_pos, p_pos = stats.shapiro(acertos_pos)
        
        capture_print(f"Teste de Normalidade (Shapiro-Wilk):")
        capture_print(f"PR√â - p-value = {p_pre:.6f}")
        capture_print(f"P√ìS - p-value = {p_pos:.6f}")
        
        if p_pre > 0.05 and p_pos > 0.05:
            t_stat, p_value = stats.ttest_rel(acertos_pos, acertos_pre)
            capture_print(f"\nTeste t pareado (dados normais):")
            capture_print(f"t-statistic: {t_stat:.4f}")
            capture_print(f"p-value: {p_value:.6f}")
        else:
            w_stat, p_value = stats.wilcoxon(acertos_pos, acertos_pre, alternative='greater')
            capture_print(f"\nTeste Wilcoxon (dados n√£o-normais):")
            capture_print(f"W-statistic: {w_stat:.4f}")
            capture_print(f"p-value: {p_value:.6f}")
        
        alpha = 0.05
        if p_value < alpha:
            capture_print(f"\n‚úì RESULTADO: H√° melhora estatisticamente significativa (p < {alpha})")
        else:
            capture_print(f"\n‚úó RESULTADO: N√£o h√° melhora estatisticamente significativa (p >= {alpha})")
            
    except Exception as e:
        capture_print(f"Erro no teste estat√≠stico: {e}")
    
    # 2. C√°lculo do Cohen's d corrigido
    try:
        diferenca = acertos_pos - acertos_pre
        # Cohen's d corrigido: usar desvio padr√£o pooled
        pooled_std = np.sqrt((acertos_pre.var() + acertos_pos.var()) / 2)
        cohen_d = diferenca.mean() / pooled_std
        
        capture_print(f"\n" + "="*80)
        capture_print("C√ÅLCULO DO EFFECT SIZE (COHEN'S d)")
        capture_print("="*80)
        capture_print(f"Diferen√ßa m√©dia: {diferenca.mean():.4f}")
        capture_print(f"Desvio padr√£o pooled: {pooled_std:.4f}")
        capture_print(f"Cohen's d: {cohen_d:.4f}")
        
        # An√°lise com benchmarks educacionais
        interpretacao = analisar_com_benchmarks(cohen_d)
        
        # Gerar recomenda√ß√µes
        recomendacoes_baseadas_benchmarks(interpretacao)
        
    except Exception as e:
        capture_print(f"Erro no c√°lculo do Cohen's d: {e}")
    
    # 3. An√°lise de melhora individual
    melhoraram = (acertos_pos > acertos_pre).sum()
    pioraram = (acertos_pos < acertos_pre).sum()
    mantiveram = (acertos_pos == acertos_pre).sum()
    
    capture_print(f"\n" + "="*60)
    capture_print("AN√ÅLISE INDIVIDUAL DE MUDAN√áA")
    capture_print("="*60)
    capture_print(f"Participantes que melhoraram: {melhoraram} ({melhoraram/len(acertos_pre)*100:.1f}%)")
    capture_print(f"Participantes que pioraram: {pioraram} ({pioraram/len(acertos_pre)*100:.1f}%)")
    capture_print(f"Participantes que mantiveram: {mantiveram} ({mantiveram/len(acertos_pre)*100:.1f}%)")
    
    # 4. An√°lise por pergunta
    capture_print(f"\n" + "="*60)
    capture_print("MELHORA POR PERGUNTA")
    capture_print("="*60)
    melhora_por_pergunta = df_pos_bool_sorted.mean() - df_pre_bool_sorted.mean()
    melhora_por_pergunta_sorted = melhora_por_pergunta.sort_values(ascending=False)
    
    capture_print("Top 10 perguntas com maior melhora:")
    for i, (pergunta, melhora) in enumerate(melhora_por_pergunta_sorted.head(10).items(), 1):
        capture_print(f"{i:2d}. {pergunta}: +{melhora:.3f} ({melhora*100:.1f}%)")
    
    capture_print("\nTop 5 perguntas com menor melhora (ou piora):")
    for i, (pergunta, melhora) in enumerate(melhora_por_pergunta_sorted.tail(5).items(), 1):
        capture_print(f"{i:2d}. {pergunta}: {melhora:+.3f} ({melhora*100:+.1f}%)")

# Refer√™ncias cient√≠ficas
capture_print(f"\n" + "="*80)
capture_print("REFER√äNCIAS CIENT√çFICAS")
capture_print("="*80)
capture_print("Cohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences (2nd ed.).")
capture_print("Lawrence Erlbaum Associates.")
capture_print("")
capture_print("Hattie, J. (2009). Visible Learning: A Synthesis of Over 800 Meta-Analyses")
capture_print("Relating to Achievement. Routledge.")
capture_print("")
capture_print("Marulis, L. M., & Neuman, S. B. (2010). The effects of vocabulary intervention")
capture_print("on young children's word learning: A meta-analysis. Review of Educational")
capture_print("Research, 80(3), 300-335.")

# Timestamp final
capture_print(f"\n" + "="*80)
capture_print(f"PIPELINE DE AN√ÅLISE ETAPA 3 FINALIZADA")
capture_print(f"Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
capture_print(f"="*80)

# Restaurar stdout
sys.stdout = original_stdout

# Salvar arquivo TXT
output_txt_path = os.path.join(str(pathlib.Path(__file__).parent.parent.parent.resolve()) + '/Data', 'pipeline_vocabulario_wordgen_etapa3_fase3.txt')

with open(output_txt_path, 'w', encoding='utf-8') as f:
    f.write(output_buffer.getvalue())

print(f"\n" + "="*80)
print(f"ETAPA 3 - AN√ÅLISE COM BENCHMARKS EDUCACIONAIS SALVA EM:")
print(f"{output_txt_path}")
print(f"="*80)

print(f"\nArquivos gerados:")
print(f"‚Ä¢ Relat√≥rio completo ETAPA 3 (TXT): {output_txt_path}")
print(f"\nAn√°lise conclu√≠da com benchmarks educacionais espec√≠ficos!")